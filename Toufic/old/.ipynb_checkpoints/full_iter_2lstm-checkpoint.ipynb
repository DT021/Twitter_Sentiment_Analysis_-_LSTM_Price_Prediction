{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "\n",
    "# from tensorflow import random\n",
    "# random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT_open</th>\n",
       "      <th>MSFT_high</th>\n",
       "      <th>MSFT_low</th>\n",
       "      <th>MSFT_close</th>\n",
       "      <th>AMD_open</th>\n",
       "      <th>AMD_high</th>\n",
       "      <th>AMD_low</th>\n",
       "      <th>AMD_close</th>\n",
       "      <th>TSLA_open</th>\n",
       "      <th>TSLA_high</th>\n",
       "      <th>...</th>\n",
       "      <th>JNJ_low</th>\n",
       "      <th>JNJ_close</th>\n",
       "      <th>REGN_open</th>\n",
       "      <th>REGN_high</th>\n",
       "      <th>REGN_low</th>\n",
       "      <th>REGN_close</th>\n",
       "      <th>GILD_open</th>\n",
       "      <th>GILD_high</th>\n",
       "      <th>GILD_low</th>\n",
       "      <th>GILD_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>24.13</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.110</td>\n",
       "      <td>23.31</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.48</td>\n",
       "      <td>19.00</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.680</td>\n",
       "      <td>59.24</td>\n",
       "      <td>23.67</td>\n",
       "      <td>23.95</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.98</td>\n",
       "      <td>35.40</td>\n",
       "      <td>35.61</td>\n",
       "      <td>34.740</td>\n",
       "      <td>34.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>23.30</td>\n",
       "      <td>23.68</td>\n",
       "      <td>22.950</td>\n",
       "      <td>23.01</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.32</td>\n",
       "      <td>25.79</td>\n",
       "      <td>30.4192</td>\n",
       "      <td>...</td>\n",
       "      <td>58.940</td>\n",
       "      <td>59.06</td>\n",
       "      <td>23.05</td>\n",
       "      <td>23.47</td>\n",
       "      <td>22.32</td>\n",
       "      <td>22.32</td>\n",
       "      <td>34.83</td>\n",
       "      <td>35.13</td>\n",
       "      <td>34.260</td>\n",
       "      <td>34.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>23.09</td>\n",
       "      <td>23.32</td>\n",
       "      <td>22.730</td>\n",
       "      <td>23.16</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.39</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>58.650</td>\n",
       "      <td>59.07</td>\n",
       "      <td>22.31</td>\n",
       "      <td>22.37</td>\n",
       "      <td>20.45</td>\n",
       "      <td>20.79</td>\n",
       "      <td>34.24</td>\n",
       "      <td>34.27</td>\n",
       "      <td>33.300</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>23.36</td>\n",
       "      <td>23.48</td>\n",
       "      <td>23.050</td>\n",
       "      <td>23.27</td>\n",
       "      <td>7.45</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.17</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.850</td>\n",
       "      <td>59.08</td>\n",
       "      <td>21.06</td>\n",
       "      <td>21.88</td>\n",
       "      <td>20.75</td>\n",
       "      <td>21.61</td>\n",
       "      <td>34.38</td>\n",
       "      <td>35.16</td>\n",
       "      <td>34.180</td>\n",
       "      <td>34.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>23.70</td>\n",
       "      <td>24.09</td>\n",
       "      <td>23.584</td>\n",
       "      <td>23.82</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6.96</td>\n",
       "      <td>7.04</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.669</td>\n",
       "      <td>59.08</td>\n",
       "      <td>22.03</td>\n",
       "      <td>22.03</td>\n",
       "      <td>21.16</td>\n",
       "      <td>21.36</td>\n",
       "      <td>35.11</td>\n",
       "      <td>35.42</td>\n",
       "      <td>34.415</td>\n",
       "      <td>34.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSFT_open  MSFT_high  MSFT_low  MSFT_close  AMD_open  AMD_high  \\\n",
       "2010-06-29      24.13      24.20    23.110       23.31      7.93      7.93   \n",
       "2010-06-30      23.30      23.68    22.950       23.01      7.58      7.65   \n",
       "2010-07-01      23.09      23.32    22.730       23.16      7.35      7.53   \n",
       "2010-07-02      23.36      23.48    23.050       23.27      7.45      7.48   \n",
       "2010-07-06      23.70      24.09    23.584       23.82      7.40      7.42   \n",
       "\n",
       "            AMD_low  AMD_close  TSLA_open  TSLA_high  ...  JNJ_low  JNJ_close  \\\n",
       "2010-06-29     7.41       7.48      19.00    25.0000  ...   58.680      59.24   \n",
       "2010-06-30     7.30       7.32      25.79    30.4192  ...   58.940      59.06   \n",
       "2010-07-01     7.10       7.39      25.00    25.9200  ...   58.650      59.07   \n",
       "2010-07-02     7.02       7.17      23.00    23.1000  ...   58.850      59.08   \n",
       "2010-07-06     6.96       7.04      20.00    20.0000  ...   58.669      59.08   \n",
       "\n",
       "            REGN_open  REGN_high  REGN_low  REGN_close  GILD_open  GILD_high  \\\n",
       "2010-06-29      23.67      23.95     22.86       22.98      35.40      35.61   \n",
       "2010-06-30      23.05      23.47     22.32       22.32      34.83      35.13   \n",
       "2010-07-01      22.31      22.37     20.45       20.79      34.24      34.27   \n",
       "2010-07-02      21.06      21.88     20.75       21.61      34.38      35.16   \n",
       "2010-07-06      22.03      22.03     21.16       21.36      35.11      35.42   \n",
       "\n",
       "            GILD_low  GILD_close  \n",
       "2010-06-29    34.740       34.97  \n",
       "2010-06-30    34.260       34.28  \n",
       "2010-07-01    33.300       34.14  \n",
       "2010-07-02    34.180       34.87  \n",
       "2010-07-06    34.415       34.77  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv into dataframe\n",
    "df = pd.read_csv(\n",
    "    Path('../data/stocks_history.csv'),\n",
    "    index_col='Unnamed: 0',\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=True\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT_close</th>\n",
       "      <th>AMD_close</th>\n",
       "      <th>TSLA_close</th>\n",
       "      <th>JNJ_close</th>\n",
       "      <th>REGN_close</th>\n",
       "      <th>GILD_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>23.31</td>\n",
       "      <td>7.48</td>\n",
       "      <td>23.89</td>\n",
       "      <td>59.24</td>\n",
       "      <td>22.98</td>\n",
       "      <td>34.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>23.01</td>\n",
       "      <td>7.32</td>\n",
       "      <td>23.83</td>\n",
       "      <td>59.06</td>\n",
       "      <td>22.32</td>\n",
       "      <td>34.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>23.16</td>\n",
       "      <td>7.39</td>\n",
       "      <td>21.96</td>\n",
       "      <td>59.07</td>\n",
       "      <td>20.79</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>23.27</td>\n",
       "      <td>7.17</td>\n",
       "      <td>19.20</td>\n",
       "      <td>59.08</td>\n",
       "      <td>21.61</td>\n",
       "      <td>34.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>23.82</td>\n",
       "      <td>7.04</td>\n",
       "      <td>16.11</td>\n",
       "      <td>59.08</td>\n",
       "      <td>21.36</td>\n",
       "      <td>34.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSFT_close  AMD_close  TSLA_close  JNJ_close  REGN_close  \\\n",
       "2010-06-29       23.31       7.48       23.89      59.24       22.98   \n",
       "2010-06-30       23.01       7.32       23.83      59.06       22.32   \n",
       "2010-07-01       23.16       7.39       21.96      59.07       20.79   \n",
       "2010-07-02       23.27       7.17       19.20      59.08       21.61   \n",
       "2010-07-06       23.82       7.04       16.11      59.08       21.36   \n",
       "\n",
       "            GILD_close  \n",
       "2010-06-29       34.97  \n",
       "2010-06-30       34.28  \n",
       "2010-07-01       34.14  \n",
       "2010-07-02       34.87  \n",
       "2010-07-06       34.77  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all columns except closing prices\n",
    "dropped_columns = [\n",
    "    'MSFT_open',\n",
    "    'MSFT_high',\n",
    "    'MSFT_low',\n",
    "    'AMD_open',\n",
    "    'AMD_high',\n",
    "    'AMD_low',\n",
    "    'TSLA_open',\n",
    "    'TSLA_high',\n",
    "    'TSLA_low',\n",
    "    'JNJ_open',\n",
    "    'JNJ_high',\n",
    "    'JNJ_low',\n",
    "    'REGN_open',\n",
    "    'REGN_high',\n",
    "    'REGN_low',\n",
    "    'GILD_open',\n",
    "    'GILD_high',\n",
    "    'GILD_low'\n",
    "]\n",
    "df.drop(columns=dropped_columns, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to store model metrics\n",
    "train_test_columns = [\n",
    "    'stock',\n",
    "    'window size',\n",
    "    'dropout fraction',\n",
    "    'epochs',\n",
    "    'batch size',\n",
    "    'mse',\n",
    "    'rmse'\n",
    "]\n",
    "train_test_eval = pd.DataFrame(columns=train_test_columns)\n",
    "\n",
    "# create dictionary to (temporarily) store model metrics during loop\n",
    "dict_train_test = {\n",
    "    'stock':[],\n",
    "    'window size':[],\n",
    "    'dropout fraction':[],\n",
    "    'epochs':[],\n",
    "    'batch size':[],\n",
    "    'mse':[],\n",
    "    'rmse':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at: 2020-07-10 02:24:42.296602\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-88dfdedb305d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mbatch_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[0;32m--> 173\u001b[0;31m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mmake_logs\u001b[0;34m(model, logs, outputs, mode, prefix)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0;34m\"\"\"Computes logs for sending to `on_batch_end` methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0mmetric_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetric_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# Add all metric names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mmetrics_names\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0mmetrics\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_metric_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_metrics_from_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m   3241\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_metrics_from_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3243\u001b[0;31m       \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3244\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_gather_children_attribute\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m       nested_layers = trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m-> 2333\u001b[0;31m           self._layers)\n\u001b[0m\u001b[1;32m   2334\u001b[0m       return list(\n\u001b[1;32m   2335\u001b[0m           itertools.chain.from_iterable(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;34m\"\"\"Filter out empty Layer-like containers and uniquify.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;31m# TODO(b/130381733): Make this an attribute in base_layer.Layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mexisting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentitySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0mto_visit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/algotrading/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# if time permitted, we would've iterated on epochs for all parameters as well (30,50,100,150),\n",
    "# as completing the 10 epochs with the below iterations took over 24 hours\n",
    "epochs = [10]\n",
    "batch_sizes = [1,10,50,150,500]\n",
    "window_sizes = [1,5,10,15,20,25,30,50]\n",
    "stock_list = [0,1,2,3,4,5]\n",
    "dropout_fractions = [0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "\n",
    "print(f'started at: {datetime.now()}')\n",
    "\n",
    "for epoch in epochs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for stock in stock_list:\n",
    "            for window_size in window_sizes:\n",
    "                for dropout_fraction in dropout_fractions:\n",
    "\n",
    "                    feature_column = stock # iterate over this to predict each stock in dataframe\n",
    "                    target_column = stock # iterate over this to predict each stock in dataframe\n",
    "                    X, y = window_data(df, window_size, feature_column, target_column)\n",
    "\n",
    "                    # Use 70% of the data for training and the remainder for testing\n",
    "                    split = int(0.7 * len(X))\n",
    "                    X_train = X[: split - 1]\n",
    "                    X_test = X[split:]\n",
    "                    y_train = y[: split - 1]\n",
    "                    y_test = y[split:]\n",
    "\n",
    "                    # Use the MinMaxScaler to scale data between 0 and 1.\n",
    "                    scaler = MinMaxScaler()\n",
    "                    scaler.fit(X)\n",
    "                    X_train = scaler.transform(X_train)\n",
    "                    X_test = scaler.transform(X_test)\n",
    "                    scaler.fit(y)\n",
    "                    y_train = scaler.transform(y_train)\n",
    "                    y_test = scaler.transform(y_test)\n",
    "\n",
    "                    # Reshape the features for the model\n",
    "                    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "                    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "                    # Define the LSTM RNN model.\n",
    "                    model = Sequential()\n",
    "                    number_units = window_size # should be equal to the size of the time window as selected above\n",
    "                    # Layer 1\n",
    "                    model.add(LSTM(\n",
    "                        units=number_units,\n",
    "                        return_sequences=True,\n",
    "                        input_shape=(X_train.shape[1], 1))\n",
    "                        )\n",
    "                    model.add(Dropout(dropout_fraction))\n",
    "                    # Layer 2\n",
    "                    model.add(LSTM(units=number_units))\n",
    "                    model.add(Dropout(dropout_fraction))\n",
    "                    # Output layer\n",
    "                    model.add(Dense(1))\n",
    "\n",
    "                    # Compile the model\n",
    "                    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "                    # Train the model\n",
    "                    model.fit(X_train, y_train, epochs=30, shuffle=False, batch_size=10, verbose=0)\n",
    "\n",
    "                    # Evaluate the model\n",
    "                    model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "                    # Make some predictions\n",
    "                    predicted = model.predict(X_test)\n",
    "\n",
    "                    # Recover the original prices instead of the scaled version\n",
    "                    predicted_prices = scaler.inverse_transform(predicted)\n",
    "                    real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "                    # Create a DataFrame of Real and Predicted values\n",
    "                    stocks = pd.DataFrame({\n",
    "                        \"Real\": real_prices.ravel(),\n",
    "                        \"Predicted\": predicted_prices.ravel()\n",
    "                    })\n",
    "\n",
    "                    # append model performance to train_test_eval dataframe\n",
    "                    dict_train_test['stock'].append(df.columns[stock])\n",
    "                    dict_train_test['window size'].append(window_size)\n",
    "                    dict_train_test['dropout fraction'].append(dropout_fraction)\n",
    "                    dict_train_test['epochs'].append(epoch)\n",
    "                    dict_train_test['batch size'].append(batch_size)\n",
    "                    dict_train_test['mse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=True))\n",
    "                    dict_train_test['rmse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=False))\n",
    "\n",
    "                    #print\n",
    "        #             print(f'stock: {df.columns[stock]}')\n",
    "        #             print(f'window size: {window_size}')\n",
    "        #             print(f'dropout fraction: {dropout_fraction}')\n",
    "        #             print(f'mse: {mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=True):.3f}')\n",
    "        #             print(f'rmse: {mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=False):.3f}')\n",
    "        #             print(datetime.now())\n",
    "\n",
    "print(f'ended at: {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>window size</th>\n",
       "      <th>dropout fraction</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch size</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT_close</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2059.369435</td>\n",
       "      <td>45.380276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT_close</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2364.568610</td>\n",
       "      <td>48.626830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT_close</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2718.782908</td>\n",
       "      <td>52.141950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT_close</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2935.851290</td>\n",
       "      <td>54.183496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT_close</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2548.619214</td>\n",
       "      <td>50.483851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock  window size  dropout fraction  epochs  batch size          mse  \\\n",
       "0  MSFT_close            1              0.10      10           1  2059.369435   \n",
       "1  MSFT_close            1              0.15      10           1  2364.568610   \n",
       "2  MSFT_close            1              0.20      10           1  2718.782908   \n",
       "3  MSFT_close            1              0.25      10           1  2935.851290   \n",
       "4  MSFT_close            1              0.30      10           1  2548.619214   \n",
       "\n",
       "        rmse  \n",
       "0  45.380276  \n",
       "1  48.626830  \n",
       "2  52.141950  \n",
       "3  54.183496  \n",
       "4  50.483851  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dictionary to dataframe\n",
    "dict_df = pd.DataFrame(dict_train_test)\n",
    "\n",
    "# concat dict_df with train_test_eval\n",
    "train_test_eval = pd.DataFrame(dict_train_test)\n",
    "train_test_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>AMD_close</th>\n",
       "      <th>GILD_close</th>\n",
       "      <th>JNJ_close</th>\n",
       "      <th>MSFT_close</th>\n",
       "      <th>REGN_close</th>\n",
       "      <th>TSLA_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">window size</th>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>18.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.773819</td>\n",
       "      <td>14.799716</td>\n",
       "      <td>14.799716</td>\n",
       "      <td>14.773819</td>\n",
       "      <td>14.799716</td>\n",
       "      <td>14.956641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dropout fraction</th>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.222857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.085840</td>\n",
       "      <td>0.085840</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.085840</td>\n",
       "      <td>0.085774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">epochs</th>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">batch size</th>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.333333</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>9.314286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.371179</td>\n",
       "      <td>4.523622</td>\n",
       "      <td>4.523622</td>\n",
       "      <td>21.371179</td>\n",
       "      <td>4.523622</td>\n",
       "      <td>13.242788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">mse</th>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.833974</td>\n",
       "      <td>10.094976</td>\n",
       "      <td>66.729138</td>\n",
       "      <td>695.081367</td>\n",
       "      <td>942.323714</td>\n",
       "      <td>7239.194739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>107.196222</td>\n",
       "      <td>7.627725</td>\n",
       "      <td>148.895341</td>\n",
       "      <td>856.139974</td>\n",
       "      <td>933.232231</td>\n",
       "      <td>12160.273935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.222121</td>\n",
       "      <td>2.532451</td>\n",
       "      <td>5.871770</td>\n",
       "      <td>7.640492</td>\n",
       "      <td>192.700920</td>\n",
       "      <td>883.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.737097</td>\n",
       "      <td>7.373901</td>\n",
       "      <td>12.928553</td>\n",
       "      <td>197.007156</td>\n",
       "      <td>387.956192</td>\n",
       "      <td>1304.990947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.498586</td>\n",
       "      <td>8.593640</td>\n",
       "      <td>15.325525</td>\n",
       "      <td>424.224591</td>\n",
       "      <td>609.153994</td>\n",
       "      <td>1933.040850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.497353</td>\n",
       "      <td>11.333571</td>\n",
       "      <td>18.799814</td>\n",
       "      <td>728.740711</td>\n",
       "      <td>1145.833574</td>\n",
       "      <td>5048.170711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>642.653882</td>\n",
       "      <td>76.956957</td>\n",
       "      <td>736.693350</td>\n",
       "      <td>4270.339278</td>\n",
       "      <td>4974.710068</td>\n",
       "      <td>68598.504454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">rmse</th>\n",
       "      <th>count</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.831787</td>\n",
       "      <td>3.079232</td>\n",
       "      <td>5.957958</td>\n",
       "      <td>22.509307</td>\n",
       "      <td>28.287458</td>\n",
       "      <td>67.394679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.616128</td>\n",
       "      <td>0.787248</td>\n",
       "      <td>5.617885</td>\n",
       "      <td>13.774252</td>\n",
       "      <td>11.984978</td>\n",
       "      <td>52.183198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.490678</td>\n",
       "      <td>1.591368</td>\n",
       "      <td>2.423173</td>\n",
       "      <td>2.764144</td>\n",
       "      <td>13.881676</td>\n",
       "      <td>29.722840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.328627</td>\n",
       "      <td>2.715492</td>\n",
       "      <td>3.595629</td>\n",
       "      <td>14.035922</td>\n",
       "      <td>19.696595</td>\n",
       "      <td>36.124658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.338401</td>\n",
       "      <td>2.931455</td>\n",
       "      <td>3.914775</td>\n",
       "      <td>20.596656</td>\n",
       "      <td>24.680385</td>\n",
       "      <td>43.966360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.030941</td>\n",
       "      <td>3.366537</td>\n",
       "      <td>4.335698</td>\n",
       "      <td>26.995198</td>\n",
       "      <td>33.849796</td>\n",
       "      <td>71.050480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.350619</td>\n",
       "      <td>8.772511</td>\n",
       "      <td>27.142096</td>\n",
       "      <td>65.347833</td>\n",
       "      <td>70.531625</td>\n",
       "      <td>261.913162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stock                    AMD_close  GILD_close   JNJ_close   MSFT_close  \\\n",
       "window size      count  144.000000   96.000000   96.000000   144.000000   \n",
       "                 mean    19.500000   19.500000   19.500000    19.500000   \n",
       "                 std     14.773819   14.799716   14.799716    14.773819   \n",
       "                 min      1.000000    1.000000    1.000000     1.000000   \n",
       "                 25%      8.750000    8.750000    8.750000     8.750000   \n",
       "                 50%     17.500000   17.500000   17.500000    17.500000   \n",
       "                 75%     26.250000   26.250000   26.250000    26.250000   \n",
       "                 max     50.000000   50.000000   50.000000    50.000000   \n",
       "dropout fraction count  144.000000   96.000000   96.000000   144.000000   \n",
       "                 mean     0.225000    0.225000    0.225000     0.225000   \n",
       "                 std      0.085689    0.085840    0.085840     0.085689   \n",
       "                 min      0.100000    0.100000    0.100000     0.100000   \n",
       "                 25%      0.150000    0.150000    0.150000     0.150000   \n",
       "                 50%      0.225000    0.225000    0.225000     0.225000   \n",
       "                 75%      0.300000    0.300000    0.300000     0.300000   \n",
       "                 max      0.350000    0.350000    0.350000     0.350000   \n",
       "epochs           count  144.000000   96.000000   96.000000   144.000000   \n",
       "                 mean    10.000000   10.000000   10.000000    10.000000   \n",
       "                 std      0.000000    0.000000    0.000000     0.000000   \n",
       "                 min     10.000000   10.000000   10.000000    10.000000   \n",
       "                 25%     10.000000   10.000000   10.000000    10.000000   \n",
       "                 50%     10.000000   10.000000   10.000000    10.000000   \n",
       "                 75%     10.000000   10.000000   10.000000    10.000000   \n",
       "                 max     10.000000   10.000000   10.000000    10.000000   \n",
       "batch size       count  144.000000   96.000000   96.000000   144.000000   \n",
       "                 mean    20.333333    5.500000    5.500000    20.333333   \n",
       "                 std     21.371179    4.523622    4.523622    21.371179   \n",
       "                 min      1.000000    1.000000    1.000000     1.000000   \n",
       "                 25%      1.000000    1.000000    1.000000     1.000000   \n",
       "                 50%     10.000000    5.500000    5.500000    10.000000   \n",
       "                 75%     50.000000   10.000000   10.000000    50.000000   \n",
       "                 max     50.000000   10.000000   10.000000    50.000000   \n",
       "mse              count  144.000000   96.000000   96.000000   144.000000   \n",
       "                 mean    67.833974   10.094976   66.729138   695.081367   \n",
       "                 std    107.196222    7.627725  148.895341   856.139974   \n",
       "                 min      2.222121    2.532451    5.871770     7.640492   \n",
       "                 25%     18.737097    7.373901   12.928553   197.007156   \n",
       "                 50%     28.498586    8.593640   15.325525   424.224591   \n",
       "                 75%     64.497353   11.333571   18.799814   728.740711   \n",
       "                 max    642.653882   76.956957  736.693350  4270.339278   \n",
       "rmse             count  144.000000   96.000000   96.000000   144.000000   \n",
       "                 mean     6.831787    3.079232    5.957958    22.509307   \n",
       "                 std      4.616128    0.787248    5.617885    13.774252   \n",
       "                 min      1.490678    1.591368    2.423173     2.764144   \n",
       "                 25%      4.328627    2.715492    3.595629    14.035922   \n",
       "                 50%      5.338401    2.931455    3.914775    20.596656   \n",
       "                 75%      8.030941    3.366537    4.335698    26.995198   \n",
       "                 max     25.350619    8.772511   27.142096    65.347833   \n",
       "\n",
       "stock                    REGN_close    TSLA_close  \n",
       "window size      count    96.000000    105.000000  \n",
       "                 mean     19.500000     18.028571  \n",
       "                 std      14.799716     14.956641  \n",
       "                 min       1.000000      1.000000  \n",
       "                 25%       8.750000      5.000000  \n",
       "                 50%      17.500000     15.000000  \n",
       "                 75%      26.250000     25.000000  \n",
       "                 max      50.000000     50.000000  \n",
       "dropout fraction count    96.000000    105.000000  \n",
       "                 mean      0.225000      0.222857  \n",
       "                 std       0.085840      0.085774  \n",
       "                 min       0.100000      0.100000  \n",
       "                 25%       0.150000      0.150000  \n",
       "                 50%       0.225000      0.200000  \n",
       "                 75%       0.300000      0.300000  \n",
       "                 max       0.350000      0.350000  \n",
       "epochs           count    96.000000    105.000000  \n",
       "                 mean     10.000000     10.000000  \n",
       "                 std       0.000000      0.000000  \n",
       "                 min      10.000000     10.000000  \n",
       "                 25%      10.000000     10.000000  \n",
       "                 50%      10.000000     10.000000  \n",
       "                 75%      10.000000     10.000000  \n",
       "                 max      10.000000     10.000000  \n",
       "batch size       count    96.000000    105.000000  \n",
       "                 mean      5.500000      9.314286  \n",
       "                 std       4.523622     13.242788  \n",
       "                 min       1.000000      1.000000  \n",
       "                 25%       1.000000      1.000000  \n",
       "                 50%       5.500000     10.000000  \n",
       "                 75%      10.000000     10.000000  \n",
       "                 max      10.000000     50.000000  \n",
       "mse              count    96.000000    105.000000  \n",
       "                 mean    942.323714   7239.194739  \n",
       "                 std     933.232231  12160.273935  \n",
       "                 min     192.700920    883.447214  \n",
       "                 25%     387.956192   1304.990947  \n",
       "                 50%     609.153994   1933.040850  \n",
       "                 75%    1145.833574   5048.170711  \n",
       "                 max    4974.710068  68598.504454  \n",
       "rmse             count    96.000000    105.000000  \n",
       "                 mean     28.287458     67.394679  \n",
       "                 std      11.984978     52.183198  \n",
       "                 min      13.881676     29.722840  \n",
       "                 25%      19.696595     36.124658  \n",
       "                 50%      24.680385     43.966360  \n",
       "                 75%      33.849796     71.050480  \n",
       "                 max      70.531625    261.913162  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_summary = train_test_eval.groupby('stock').describe().transpose()\n",
    "eval_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>window size</th>\n",
       "      <th>dropout fraction</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch size</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD_close</td>\n",
       "      <td>50</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.222121</td>\n",
       "      <td>1.490678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GILD_close</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.532451</td>\n",
       "      <td>1.591368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JNJ_close</td>\n",
       "      <td>50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5.871770</td>\n",
       "      <td>2.423173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT_close</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7.640492</td>\n",
       "      <td>2.764144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REGN_close</td>\n",
       "      <td>30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>192.700920</td>\n",
       "      <td>13.881676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TSLA_close</td>\n",
       "      <td>30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>883.447214</td>\n",
       "      <td>29.722840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock  window size  dropout fraction  epochs  batch size         mse  \\\n",
       "0   AMD_close           50              0.15      10           1    2.222121   \n",
       "1  GILD_close            1              0.10      10          10    2.532451   \n",
       "2   JNJ_close           50              0.20      10          10    5.871770   \n",
       "3  MSFT_close           50              0.10      10           1    7.640492   \n",
       "4  REGN_close           30              0.25      10          10  192.700920   \n",
       "5  TSLA_close           30              0.30      10          10  883.447214   \n",
       "\n",
       "        rmse  \n",
       "0   1.490678  \n",
       "1   1.591368  \n",
       "2   2.423173  \n",
       "3   2.764144  \n",
       "4  13.881676  \n",
       "5  29.722840  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_best_performers = {\n",
    "    'stock':[],\n",
    "    'window size':[],\n",
    "    'dropout fraction':[],\n",
    "    'epochs':[],\n",
    "    'batch size':[],\n",
    "    'mse':[],\n",
    "    'rmse':[]\n",
    "}\n",
    "\n",
    "for i in [1.490678,1.591368,2.423173,2.764144,13.881676,29.722840]:\n",
    "#     train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i]]\n",
    "\n",
    "    dict_best_performers['stock'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],0].values[0])\n",
    "    dict_best_performers['window size'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],1].values[0])\n",
    "    dict_best_performers['dropout fraction'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],2].values[0])\n",
    "    dict_best_performers['epochs'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],3].values[0])\n",
    "    dict_best_performers['batch size'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],4].values[0])\n",
    "    dict_best_performers['mse'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],5].values[0])\n",
    "    dict_best_performers['rmse'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],6].values[0])\n",
    "\n",
    "df_best_performers = pd.DataFrame(dict_best_performers)\n",
    "df_best_performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at: 2020-07-10 20:24:53.802010\n",
      "ended at: 2020-07-11 05:16:24.987783\n"
     ]
    }
   ],
   "source": [
    "df_epoch_iters_iters = {\n",
    "    'stock':[],\n",
    "    'window size':[],\n",
    "    'dropout fraction':[],\n",
    "    'epochs':[],\n",
    "    'batch size':[],\n",
    "    'mse':[],\n",
    "    'rmse':[]\n",
    "}\n",
    "\n",
    "epochs = [30,50,100,150]\n",
    "\n",
    "print(f'started at: {datetime.now()}')\n",
    "\n",
    "for epoch in epochs:\n",
    "    for index, row in df_best_performers.iterrows():\n",
    "\n",
    "        feature_column = df.columns.get_loc(row['stock'])\n",
    "        target_column = df.columns.get_loc(row['stock'])\n",
    "        X, y = window_data(df, row['window size'], feature_column, target_column)\n",
    "\n",
    "        # Use 70% of the data for training and the remainder for testing\n",
    "        split = int(0.7 * len(X))\n",
    "        X_train = X[: split - 1]\n",
    "        X_test = X[split:]\n",
    "        y_train = y[: split - 1]\n",
    "        y_test = y[split:]\n",
    "\n",
    "        # Use the MinMaxScaler to scale data between 0 and 1.\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        scaler.fit(y)\n",
    "        y_train = scaler.transform(y_train)\n",
    "        y_test = scaler.transform(y_test)\n",
    "\n",
    "        # Reshape the features for the model\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "        # Define the LSTM RNN model.\n",
    "        model = Sequential()\n",
    "        # Layer 1\n",
    "        model.add(LSTM(\n",
    "            units=row['window size'],\n",
    "            return_sequences=True,\n",
    "            input_shape=(X_train.shape[1], 1))\n",
    "            )\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Layer 2\n",
    "        model.add(LSTM(units=row['window size']))\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Output layer\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=epoch, shuffle=False, batch_size=row['batch size'], verbose=0)\n",
    "\n",
    "        # Evaluate the model\n",
    "        loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        # Make some predictions\n",
    "        predicted = model.predict(X_test)\n",
    "\n",
    "        # Recover the original prices instead of the scaled version\n",
    "        predicted_prices = scaler.inverse_transform(predicted)\n",
    "        real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Create a DataFrame of Real and Predicted values\n",
    "        stocks = pd.DataFrame({\n",
    "            \"Real\": real_prices.ravel(),\n",
    "            \"Predicted\": predicted_prices.ravel()\n",
    "        })\n",
    "\n",
    "        # append model performance to train_test_eval dataframe\n",
    "        epoch_iters['stock'].append(row['stock'])\n",
    "        epoch_iters['window size'].append(row['window size'])\n",
    "        epoch_iters['dropout fraction'].append(row['dropout fraction'])\n",
    "        epoch_iters['epochs'].append(epoch)\n",
    "        epoch_iters['batch size'].append(row['batch size'])\n",
    "        epoch_iters['mse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=True))\n",
    "        epoch_iters['rmse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=False))\n",
    "\n",
    "print(f'ended at: {datetime.now()}')\n",
    "\n",
    "df_epoch_iters = pd.DataFrame(epoch_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_epoch_iters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2c705f933e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_epoch_iters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_epoch_iters' is not defined"
     ]
    }
   ],
   "source": [
    "df_epoch_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
