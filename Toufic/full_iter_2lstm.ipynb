{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "\n",
    "# from tensorflow import random\n",
    "# random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT_open</th>\n",
       "      <th>MSFT_high</th>\n",
       "      <th>MSFT_low</th>\n",
       "      <th>MSFT_close</th>\n",
       "      <th>AMD_open</th>\n",
       "      <th>AMD_high</th>\n",
       "      <th>AMD_low</th>\n",
       "      <th>AMD_close</th>\n",
       "      <th>TSLA_open</th>\n",
       "      <th>TSLA_high</th>\n",
       "      <th>...</th>\n",
       "      <th>JNJ_low</th>\n",
       "      <th>JNJ_close</th>\n",
       "      <th>REGN_open</th>\n",
       "      <th>REGN_high</th>\n",
       "      <th>REGN_low</th>\n",
       "      <th>REGN_close</th>\n",
       "      <th>GILD_open</th>\n",
       "      <th>GILD_high</th>\n",
       "      <th>GILD_low</th>\n",
       "      <th>GILD_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>24.13</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.110</td>\n",
       "      <td>23.31</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.48</td>\n",
       "      <td>19.00</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.680</td>\n",
       "      <td>59.24</td>\n",
       "      <td>23.67</td>\n",
       "      <td>23.95</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.98</td>\n",
       "      <td>35.40</td>\n",
       "      <td>35.61</td>\n",
       "      <td>34.740</td>\n",
       "      <td>34.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>23.30</td>\n",
       "      <td>23.68</td>\n",
       "      <td>22.950</td>\n",
       "      <td>23.01</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.32</td>\n",
       "      <td>25.79</td>\n",
       "      <td>30.4192</td>\n",
       "      <td>...</td>\n",
       "      <td>58.940</td>\n",
       "      <td>59.06</td>\n",
       "      <td>23.05</td>\n",
       "      <td>23.47</td>\n",
       "      <td>22.32</td>\n",
       "      <td>22.32</td>\n",
       "      <td>34.83</td>\n",
       "      <td>35.13</td>\n",
       "      <td>34.260</td>\n",
       "      <td>34.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>23.09</td>\n",
       "      <td>23.32</td>\n",
       "      <td>22.730</td>\n",
       "      <td>23.16</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.39</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>58.650</td>\n",
       "      <td>59.07</td>\n",
       "      <td>22.31</td>\n",
       "      <td>22.37</td>\n",
       "      <td>20.45</td>\n",
       "      <td>20.79</td>\n",
       "      <td>34.24</td>\n",
       "      <td>34.27</td>\n",
       "      <td>33.300</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>23.36</td>\n",
       "      <td>23.48</td>\n",
       "      <td>23.050</td>\n",
       "      <td>23.27</td>\n",
       "      <td>7.45</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.02</td>\n",
       "      <td>7.17</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.850</td>\n",
       "      <td>59.08</td>\n",
       "      <td>21.06</td>\n",
       "      <td>21.88</td>\n",
       "      <td>20.75</td>\n",
       "      <td>21.61</td>\n",
       "      <td>34.38</td>\n",
       "      <td>35.16</td>\n",
       "      <td>34.180</td>\n",
       "      <td>34.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>23.70</td>\n",
       "      <td>24.09</td>\n",
       "      <td>23.584</td>\n",
       "      <td>23.82</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6.96</td>\n",
       "      <td>7.04</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.669</td>\n",
       "      <td>59.08</td>\n",
       "      <td>22.03</td>\n",
       "      <td>22.03</td>\n",
       "      <td>21.16</td>\n",
       "      <td>21.36</td>\n",
       "      <td>35.11</td>\n",
       "      <td>35.42</td>\n",
       "      <td>34.415</td>\n",
       "      <td>34.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSFT_open  MSFT_high  MSFT_low  MSFT_close  AMD_open  AMD_high  \\\n",
       "2010-06-29      24.13      24.20    23.110       23.31      7.93      7.93   \n",
       "2010-06-30      23.30      23.68    22.950       23.01      7.58      7.65   \n",
       "2010-07-01      23.09      23.32    22.730       23.16      7.35      7.53   \n",
       "2010-07-02      23.36      23.48    23.050       23.27      7.45      7.48   \n",
       "2010-07-06      23.70      24.09    23.584       23.82      7.40      7.42   \n",
       "\n",
       "            AMD_low  AMD_close  TSLA_open  TSLA_high  ...  JNJ_low  JNJ_close  \\\n",
       "2010-06-29     7.41       7.48      19.00    25.0000  ...   58.680      59.24   \n",
       "2010-06-30     7.30       7.32      25.79    30.4192  ...   58.940      59.06   \n",
       "2010-07-01     7.10       7.39      25.00    25.9200  ...   58.650      59.07   \n",
       "2010-07-02     7.02       7.17      23.00    23.1000  ...   58.850      59.08   \n",
       "2010-07-06     6.96       7.04      20.00    20.0000  ...   58.669      59.08   \n",
       "\n",
       "            REGN_open  REGN_high  REGN_low  REGN_close  GILD_open  GILD_high  \\\n",
       "2010-06-29      23.67      23.95     22.86       22.98      35.40      35.61   \n",
       "2010-06-30      23.05      23.47     22.32       22.32      34.83      35.13   \n",
       "2010-07-01      22.31      22.37     20.45       20.79      34.24      34.27   \n",
       "2010-07-02      21.06      21.88     20.75       21.61      34.38      35.16   \n",
       "2010-07-06      22.03      22.03     21.16       21.36      35.11      35.42   \n",
       "\n",
       "            GILD_low  GILD_close  \n",
       "2010-06-29    34.740       34.97  \n",
       "2010-06-30    34.260       34.28  \n",
       "2010-07-01    33.300       34.14  \n",
       "2010-07-02    34.180       34.87  \n",
       "2010-07-06    34.415       34.77  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv into dataframe\n",
    "df = pd.read_csv(\n",
    "    Path('../data/stocks_history.csv'),\n",
    "    index_col='Unnamed: 0',\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=True\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT_close</th>\n",
       "      <th>AMD_close</th>\n",
       "      <th>TSLA_close</th>\n",
       "      <th>JNJ_close</th>\n",
       "      <th>REGN_close</th>\n",
       "      <th>GILD_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>23.31</td>\n",
       "      <td>7.48</td>\n",
       "      <td>23.89</td>\n",
       "      <td>59.24</td>\n",
       "      <td>22.98</td>\n",
       "      <td>34.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>23.01</td>\n",
       "      <td>7.32</td>\n",
       "      <td>23.83</td>\n",
       "      <td>59.06</td>\n",
       "      <td>22.32</td>\n",
       "      <td>34.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>23.16</td>\n",
       "      <td>7.39</td>\n",
       "      <td>21.96</td>\n",
       "      <td>59.07</td>\n",
       "      <td>20.79</td>\n",
       "      <td>34.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>23.27</td>\n",
       "      <td>7.17</td>\n",
       "      <td>19.20</td>\n",
       "      <td>59.08</td>\n",
       "      <td>21.61</td>\n",
       "      <td>34.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>23.82</td>\n",
       "      <td>7.04</td>\n",
       "      <td>16.11</td>\n",
       "      <td>59.08</td>\n",
       "      <td>21.36</td>\n",
       "      <td>34.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSFT_close  AMD_close  TSLA_close  JNJ_close  REGN_close  \\\n",
       "2010-06-29       23.31       7.48       23.89      59.24       22.98   \n",
       "2010-06-30       23.01       7.32       23.83      59.06       22.32   \n",
       "2010-07-01       23.16       7.39       21.96      59.07       20.79   \n",
       "2010-07-02       23.27       7.17       19.20      59.08       21.61   \n",
       "2010-07-06       23.82       7.04       16.11      59.08       21.36   \n",
       "\n",
       "            GILD_close  \n",
       "2010-06-29       34.97  \n",
       "2010-06-30       34.28  \n",
       "2010-07-01       34.14  \n",
       "2010-07-02       34.87  \n",
       "2010-07-06       34.77  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all columns except closing prices\n",
    "dropped_columns = [\n",
    "    'MSFT_open',\n",
    "    'MSFT_high',\n",
    "    'MSFT_low',\n",
    "    'AMD_open',\n",
    "    'AMD_high',\n",
    "    'AMD_low',\n",
    "    'TSLA_open',\n",
    "    'TSLA_high',\n",
    "    'TSLA_low',\n",
    "    'JNJ_open',\n",
    "    'JNJ_high',\n",
    "    'JNJ_low',\n",
    "    'REGN_open',\n",
    "    'REGN_high',\n",
    "    'REGN_low',\n",
    "    'GILD_open',\n",
    "    'GILD_high',\n",
    "    'GILD_low'\n",
    "]\n",
    "df.drop(columns=dropped_columns, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to store model metrics\n",
    "train_test_columns = [\n",
    "    'stock',\n",
    "    'window size',\n",
    "    'dropout fraction',\n",
    "    'epochs',\n",
    "    'batch size',\n",
    "    'mse',\n",
    "    'rmse'\n",
    "]\n",
    "train_test_eval = pd.DataFrame(columns=train_test_columns)\n",
    "\n",
    "# create dictionary to (temporarily) store model metrics during loop\n",
    "dict_train_test = {\n",
    "    'stock':[],\n",
    "    'window size':[],\n",
    "    'dropout fraction':[],\n",
    "    'epochs':[],\n",
    "    'batch size':[],\n",
    "    'mse':[],\n",
    "    'rmse':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at: 2020-07-15 07:25:46.368265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# if time permitted, we would've iterated on epochs for all parameters as well (30,50,100,150),\n",
    "# as completing the 10 epochs with the below iterations took over 24 hours\n",
    "epochs = [10]\n",
    "batch_sizes = [1,10,50,150,500]\n",
    "window_sizes = [1,5,10,15,20,25,30,50]\n",
    "stock_list = [0,1,2,3,4,5]\n",
    "dropout_fractions = [0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "\n",
    "print(f'started at: {datetime.now()}')\n",
    "\n",
    "for epoch in epochs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for stock in stock_list:\n",
    "            for window_size in window_sizes:\n",
    "                for dropout_fraction in dropout_fractions:\n",
    "\n",
    "                    feature_column = stock # iterate over this to predict each stock in dataframe\n",
    "                    target_column = stock # iterate over this to predict each stock in dataframe\n",
    "                    X, y = window_data(df, window_size, feature_column, target_column)\n",
    "\n",
    "                    # Use 70% of the data for training and the remainder for testing\n",
    "                    split = int(0.7 * len(X))\n",
    "                    X_train = X[: split - 1]\n",
    "                    X_test = X[split:]\n",
    "                    y_train = y[: split - 1]\n",
    "                    y_test = y[split:]\n",
    "\n",
    "                    # Use the MinMaxScaler to scale data between 0 and 1.\n",
    "                    scaler = MinMaxScaler()\n",
    "                    scaler.fit(X)\n",
    "                    X_train = scaler.transform(X_train)\n",
    "                    X_test = scaler.transform(X_test)\n",
    "                    scaler.fit(y)\n",
    "                    y_train = scaler.transform(y_train)\n",
    "                    y_test = scaler.transform(y_test)\n",
    "\n",
    "                    # Reshape the features for the model\n",
    "                    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "                    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "                    # Define the LSTM RNN model.\n",
    "                    model = Sequential()\n",
    "                    number_units = window_size # should be equal to the size of the time window as selected above\n",
    "                    # Layer 1\n",
    "                    model.add(LSTM(\n",
    "                        units=number_units,\n",
    "                        return_sequences=True,\n",
    "                        input_shape=(X_train.shape[1], 1))\n",
    "                        )\n",
    "                    model.add(Dropout(dropout_fraction))\n",
    "                    # Layer 2\n",
    "                    model.add(LSTM(units=number_units))\n",
    "                    model.add(Dropout(dropout_fraction))\n",
    "                    # Output layer\n",
    "                    model.add(Dense(1))\n",
    "\n",
    "                    # Compile the model\n",
    "                    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "                    # Train the model\n",
    "                    model.fit(X_train, y_train, epochs=30, shuffle=False, batch_size=10, verbose=0)\n",
    "\n",
    "                    # Evaluate the model\n",
    "                    model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "                    # Make some predictions\n",
    "                    predicted = model.predict(X_test)\n",
    "\n",
    "                    # Recover the original prices instead of the scaled version\n",
    "                    predicted_prices = scaler.inverse_transform(predicted)\n",
    "                    real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "                    # Create a DataFrame of Real and Predicted values\n",
    "                    stocks = pd.DataFrame({\n",
    "                        \"Real\": real_prices.ravel(),\n",
    "                        \"Predicted\": predicted_prices.ravel()\n",
    "                    })\n",
    "\n",
    "                    # append model performance to train_test_eval dataframe\n",
    "                    dict_train_test['stock'].append(df.columns[stock])\n",
    "                    dict_train_test['window size'].append(window_size)\n",
    "                    dict_train_test['dropout fraction'].append(dropout_fraction)\n",
    "                    dict_train_test['epochs'].append(epoch)\n",
    "                    dict_train_test['batch size'].append(batch_size)\n",
    "                    dict_train_test['mse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=True))\n",
    "                    dict_train_test['rmse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=False))\n",
    "\n",
    "                    #print\n",
    "        #             print(f'stock: {df.columns[stock]}')\n",
    "        #             print(f'window size: {window_size}')\n",
    "        #             print(f'dropout fraction: {dropout_fraction}')\n",
    "        #             print(f'mse: {mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=True):.3f}')\n",
    "        #             print(f'rmse: {mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=False):.3f}')\n",
    "        #             print(datetime.now())\n",
    "\n",
    "print(f'ended at: {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dictionary to dataframe\n",
    "dict_df = pd.DataFrame(dict_train_test)\n",
    "\n",
    "# concat dict_df with train_test_eval\n",
    "train_test_eval = pd.DataFrame(dict_train_test)\n",
    "train_test_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_summary = train_test_eval.groupby('stock').describe().transpose()\n",
    "eval_summary.to_csv('eval_summary_2lstm.csv')\n",
    "eval_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_best_performers = {\n",
    "    'stock':[],\n",
    "    'window size':[],\n",
    "    'dropout fraction':[],\n",
    "    'epochs':[],\n",
    "    'batch size':[],\n",
    "    'mse':[],\n",
    "    'rmse':[]\n",
    "}\n",
    "\n",
    "for i in [1.490678,1.591368,2.423173,2.764144,13.881676,29.722840]:\n",
    "#     train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i]]\n",
    "\n",
    "    dict_best_performers['stock'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],0].values[0])\n",
    "    dict_best_performers['window size'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],1].values[0])\n",
    "    dict_best_performers['dropout fraction'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],2].values[0])\n",
    "    dict_best_performers['epochs'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],3].values[0])\n",
    "    dict_best_performers['batch size'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],4].values[0])\n",
    "    dict_best_performers['mse'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],5].values[0])\n",
    "    dict_best_performers['rmse'].append(train_test_eval.iloc[train_test_eval.index[train_test_eval['rmse'].round(6)==i],6].values[0])\n",
    "\n",
    "df_best_performers = pd.DataFrame(dict_best_performers)\n",
    "df_best_performers.to_csv('df_best_performers_2lstm.csv')\n",
    "df_best_performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epoch_iters_iters = {\n",
    "    'stock':[],\n",
    "    'window size':[],\n",
    "    'dropout fraction':[],\n",
    "    'epochs':[],\n",
    "    'batch size':[],\n",
    "    'mse':[],\n",
    "    'rmse':[]\n",
    "}\n",
    "\n",
    "epochs = [30,50,100,150]\n",
    "\n",
    "print(f'started at: {datetime.now()}')\n",
    "\n",
    "for epoch in epochs:\n",
    "    for index, row in df_best_performers.iterrows():\n",
    "\n",
    "        feature_column = df.columns.get_loc(row['stock'])\n",
    "        target_column = df.columns.get_loc(row['stock'])\n",
    "        X, y = window_data(df, row['window size'], feature_column, target_column)\n",
    "\n",
    "        # Use 70% of the data for training and the remainder for testing\n",
    "        split = int(0.7 * len(X))\n",
    "        X_train = X[: split - 1]\n",
    "        X_test = X[split:]\n",
    "        y_train = y[: split - 1]\n",
    "        y_test = y[split:]\n",
    "\n",
    "        # Use the MinMaxScaler to scale data between 0 and 1.\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        scaler.fit(y)\n",
    "        y_train = scaler.transform(y_train)\n",
    "        y_test = scaler.transform(y_test)\n",
    "\n",
    "        # Reshape the features for the model\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "        # Define the LSTM RNN model.\n",
    "        model = Sequential()\n",
    "        # Layer 1\n",
    "        model.add(LSTM(\n",
    "            units=row['window size'],\n",
    "            return_sequences=True,\n",
    "            input_shape=(X_train.shape[1], 1))\n",
    "            )\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Layer 2\n",
    "        model.add(LSTM(units=row['window size']))\n",
    "        model.add(Dropout(dropout_fraction))\n",
    "        # Output layer\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=epoch, shuffle=False, batch_size=row['batch size'], verbose=0)\n",
    "\n",
    "        # Evaluate the model\n",
    "        loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        # Make some predictions\n",
    "        predicted = model.predict(X_test)\n",
    "\n",
    "        # Recover the original prices instead of the scaled version\n",
    "        predicted_prices = scaler.inverse_transform(predicted)\n",
    "        real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Create a DataFrame of Real and Predicted values\n",
    "        stocks = pd.DataFrame({\n",
    "            \"Real\": real_prices.ravel(),\n",
    "            \"Predicted\": predicted_prices.ravel()\n",
    "        })\n",
    "\n",
    "        # append model performance to train_test_eval dataframe\n",
    "        epoch_iters['stock'].append(row['stock'])\n",
    "        epoch_iters['window size'].append(row['window size'])\n",
    "        epoch_iters['dropout fraction'].append(row['dropout fraction'])\n",
    "        epoch_iters['epochs'].append(epoch)\n",
    "        epoch_iters['batch size'].append(row['batch size'])\n",
    "        epoch_iters['mse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=True))\n",
    "        epoch_iters['rmse'].append(mean_squared_error(stocks.iloc[:,0],stocks.iloc[:,1], squared=False))\n",
    "\n",
    "print(f'ended at: {datetime.now()}')\n",
    "\n",
    "df_epoch_iters = pd.DataFrame(epoch_iters)\n",
    "df_epoch_iters.to_csv('df_epoch_iters_2lstm.csv')\n",
    "df_epoch_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
